---
title: "mirai - Torch Integration"
vignette: >
  %\VignetteIndexEntry{mirai - Torch Integration}
  %\VignetteEngine{knitr::knitr}
  %\VignetteEncoding{UTF-8}
---



### Torch Integration

Custom serialization functions may be registered to handle external pointer type reference objects.

This allows tensors from the [`torch`](https://cran.r-project.org/package=torch) package to be used seamlessly in 'mirai' computations.

1. Register the serialization and unserialization functions as a list supplied to the 'refhook' argument of `serialization()`.

2. Set up dameons - this may be done before or after setting `serialization()`.

3. Use `everywhere()` to make the 'torch' package available on all dameons (for convenience, optional).


```r
library(torch)
serialization(refhook = list(torch:::torch_serialize, torch::torch_load))
daemons(1)
#> [1] 1
everywhere(library(torch))
```

The below example creates a convolutional neural network using `torch::nn_module()`, which is then passed a set of parameters and initialized within a 'mirai'.


```r
model <- nn_module(
  initialize = function(in_size, out_size) {
    self$conv1 <- nn_conv2d(in_size, out_size, 5)
    self$conv2 <- nn_conv2d(in_size, out_size, 5)
  },
  forward = function(x) {
    x <- self$conv1(x)
    x <- nnf_relu(x)
    x <- self$conv2(x)
    x <- nnf_relu(x)
    x
  }
)

params <- list(in_size = 1, out_size = 20)

m <- mirai(do.call(model, params), .args = list(model, params))
call_mirai(m)$data
#> An `nn_module` containing 1,040 parameters.
#> 
#> ── Modules ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────
#> • conv1: <nn_conv2d> #520 parameters
#> • conv2: <nn_conv2d> #520 parameters
```
The returned model is an object containing many tensor elements.


```r
m$data$parameters$conv1.weight
#> torch_tensor
#> (1,1,.,.) = 
#>  -0.1205 -0.1757 -0.0501  0.1389  0.0922
#>  -0.1649 -0.1273  0.0191  0.1186 -0.0943
#>   0.1665 -0.0876 -0.1023  0.0301  0.1141
#>   0.0322  0.0580  0.0123 -0.0415 -0.1614
#>   0.1639  0.1523 -0.1057 -0.0188 -0.0248
#> 
#> (2,1,.,.) = 
#>  -0.1008  0.1984 -0.0736 -0.1917  0.1427
#>   0.0703  0.0128  0.0620 -0.0524 -0.0565
#>   0.0750 -0.0657  0.1786 -0.1733 -0.0639
#>  -0.1578  0.1989  0.1473 -0.1071  0.0607
#>  -0.1334 -0.1061 -0.1487 -0.1097 -0.0244
#> 
#> (3,1,.,.) = 
#>   0.0814  0.1406  0.0929  0.0101  0.0254
#>   0.0645  0.0082 -0.1432 -0.0091 -0.1674
#>   0.0242 -0.1321 -0.1690 -0.0254 -0.1345
#>  -0.1011  0.0083 -0.1139 -0.0948 -0.0941
#>  -0.0352 -0.1540  0.0097 -0.1977  0.0735
#> 
#> (4,1,.,.) = 
#>   0.1920  0.1211  0.1399  0.1913 -0.0115
#>  -0.1858  0.0491 -0.0151 -0.0219 -0.1164
#>  -0.1854  0.0309 -0.0076  0.0381 -0.0900
#>   0.0488  0.1269  0.0352  0.0338 -0.0510
#>  -0.0565 -0.0516 -0.0590  0.1656 -0.1994
#> 
#> (5,1,.,.) = 
#>   0.1760 -0.0951 -0.0583  0.1938  0.0130
#> ... [the output was truncated (use n=-1 to disable)]
#> [ CPUFloatType{20,1,5,5} ][ requires_grad = TRUE ]
```

The model parameters can then be further passed to an optimiser, with that also initialized within a 'mirai' process.


```r
optim <- mirai(optim_rmsprop(params = params), params = m$data$parameters)
call_mirai(optim)$data
#> <optim_rmsprop>
#>   Inherits from: <torch_optimizer>
#>   Public:
#>     add_param_group: function (param_group) 
#>     clone: function (deep = FALSE) 
#>     defaults: list
#>     initialize: function (params, lr = 0.01, alpha = 0.99, eps = 1e-08, weight_decay = 0, 
#>     load_state_dict: function (state_dict, ..., .refer_to_state_dict = FALSE) 
#>     param_groups: list
#>     state: State, R6
#>     state_dict: function () 
#>     step: function (closure = NULL) 
#>     zero_grad: function () 
#>   Private:
#>     step_helper: function (closure, loop_fun)

daemons(0)
#> [1] 0
```
Above, tensors and complex objects containing tensors were passed seamlessly between host and daemon processes, in the same way as any other R object.

The implementation leverages R's own native 'refhook' mechanism to allow such completely transparent usage, and is designed to be fast and efficient using the serialization methods from the 'torch' package directly, minimising data copies where possible.
