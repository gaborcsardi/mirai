---
title: "mirai - Plumber Integration"
vignette: >
  %\VignetteIndexEntry{mirai - Plumber Integration}
  %\VignetteEngine{knitr::knitr}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  out.width = "100%"
)
```

### Plumber Integration

'mirai' supplies its own `as.promise()` method, allowing it to be used as a promise.

A 'mirai' may be piped directly using the promise pipe `&...>%`, which implicitly calls `as.promise()` on the 'mirai', or converted into a promise by `as.promise()`, which then allows using the methods `$then()`, `$finally()` etc.

Below we provide example usage of how to use mirai as an async distributed backend for {plumber} pipelines.

The plumber router code is run in a daemon process itself so that it does not block the interactive process. It is important to set up this daemon with the argument `autoexit = tools::SIGINT`, so that the plumber server is interrupted and exits cleanly when we tear it down.

#### Example GET Endpoint

The /echo endpoint takes a GET request, sleeps for 1 second (simulating an expensive computation) and just returns the 'msg' request header together with a timestamp and the process ID of the process it is run on.

```{r get}
library(mirai)

daemons(1L, dispatcher = FALSE, autoexit = tools::SIGINT)

m <- mirai({
  library(plumber)
  library(promises) # to provide the promise pipe
  library(mirai)

  daemons(4L, dispatcher = FALSE) # handles 4 requests simultaneously
  # does not use dispatcher (suitable when all requests require similar compute)

  pr() |>
    pr_get(
      "/echo",
      function(req, res) {
        mirai(
          {
            Sys.sleep(1L)
            list(status = 200L, body = list(time = format(Sys.time()),
                                            msg = req[["HEADERS"]][["msg"]],
                                            pid = Sys.getpid()))
          },
          req = req
        ) %...>% (function(x) {
          res$status <- x$status
          res$body <- x$body
        })
      }
    ) |>
    pr_run(host = "127.0.0.1", port = 8985)
})
```
```{r sleep2, echo=FALSE}
Sys.sleep(2)
```
The API can be queried using an async HTTP client such as `nanonext::ncurl_aio()`.

Here, all 8 requests are submitted at once, but we note that that responses have differing timestamps as only 4 can be processed at any given time.

```{r queryapi}
library(nanonext)
res <- lapply(1:8,
              function(i) ncurl_aio("http://127.0.0.1:8985/echo",
                                    headers = c(msg = as.character(i))))
res <- lapply(res, call_aio)
for (r in res) print(r$data)

daemons(0)
```

#### Example POST Endpoint

Below is a demonstration of the equivalent using a POST endpoint, accepting a JSON instruction sent as request data.

It is important to note in this case that `req$postBody` should be accessed in the router process and passed in as an argument to the 'mirai' as this is retrieved using a connection that is not serializable.

```{r post}
library(mirai)

daemons(1L, dispatcher = FALSE, autoexit = tools::SIGINT)

m <- mirai({
  library(plumber)
  library(promises) # to provide the promise pipe
  library(mirai)

  daemons(4L) # handles 4 requests simultaneously
  # uses dispatcher (suitable for requests with differing compute lengths)

  pr() |>
    pr_post(
      "/echo",
      function(req, res) {
        mirai(
          {
            Sys.sleep(1L) # simulate expensive computation
            list(status = 200L,
                 body = list(time = format(Sys.time()),
                             msg = jsonlite::fromJSON(data)[["msg"]],
                             pid = Sys.getpid()))
          },
          data = req$postBody
        ) %...>% (function(x) {
          res$status <- x$status
          res$body <- x$body
        })
      }
    ) |>
    pr_run(host = "127.0.0.1", port = 8986)
})
```
```{r sleep2post, echo=FALSE}
Sys.sleep(2)
```
Querying the endpoint produces the same set of outputs as the previous example.

```{r queryapipost}
library(nanonext)
res <- lapply(1:8,
              function(i) ncurl_aio("http://127.0.0.1:8986/echo",
                                    method = "POST",
                                    data = sprintf('{"msg":"%d"}', i)))
res <- lapply(res, call_aio)
for (r in res) print(r$data)

daemons(0)
```
